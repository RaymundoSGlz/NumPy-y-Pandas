---
title: "Pandas"
date: "`r format(Sys.time(), '%B %Y')`"
output: 
  html_document:
    toc: true # table of content true
    toc_depth: 4  # upto three depths of headings (specified by #, ## and ###)
    theme: united  # many options for theme, this one is my favorite.
---

```{r setup, include=FALSE}
library(reticulate)
```

Pandas es una librería de Python especializada en el **manejo y análisis de estructura de datos**, el nombre pandas viene de "**Panel data**". Se caracteriza por su:

-   Velocidad
-   Poco código
-   Múltiples formatos de archivos
-   Alineación inteligente

La forma común de importarla es

```{python}
import pandas as pd
```

## Series y DataFrames

### Series

Son arreglos **unidimensionales** indexados

#### Series con index personalizados

```{python}
psg_players = pd.Series(['Navas','Mbappe','Neymar','Messi'], index=[1,7,10,30])
psg_players
```
#### Series con index default

```{python}
psg_players = pd.Series(['Navas','Mbappe','Neymar','Messi'])
psg_players
```

#### Series con diccionario JSON

```{python}
dictionary = {1: 'Navas', 7:'Mbappe', 10:'Neymar', 30:'Messi'}
pd.Series(dictionary)
```

### Slicing

Podemos acceder a los datos de la misma forma que lo hacemos con NumPy

```{python}
psg_players[0:3]
```

### DataFrame matricial

Podemos trabajar con estructuras matriciales

```{python}
dictionary = {'jugador':['Navas','Mbappe','Neymar','Messi'],
'altura':[183.0, 170.0, 170.0, 165.0],
'goles':[2, 200, 200, 200]
}
dictionary
```

#### DataFrame con index personalizado

```{python}
pd.DataFrame(dictionary, index=[1,7,10,30])
```

#### DataFrame con index default

```{python}
pd.DataFrame(dictionary)
```

### Visualizar ejes en DataFrame

```{python}
df_Players = pd.DataFrame(dictionary)
df_Players
```

#### Visualizar Data por columnas

```{python}
df_Players.columns
```

#### Visualizar Data por indices

##### Indice default

```{python}
df_Players.index
```

##### Indice personalizado

```{python}
df_Players = pd.DataFrame(dictionary, index=[1,7,10,30])
df_Players.index
```

## Leer archivos CSV y JSON

Podemos cargar archivos a través de URL, JSON, HTML, etc.

### CSV

```{python}
csv_per_default = pd.read_csv('./Data/bestsellers-with-categories.csv')
csv_per_default
```
#### Cambiar el encabezado

Lo podemos hacer con “**Header**”, este pondrá de encabezado los valores que tenga en esa posición.

```{python}
pd.read_csv('./Data/bestsellers-with-categories.csv', sep=",", header= 2)
```

#### Cambiar el nombre de las columnas
 
Lo podemos hacer con “**names**”

```{python}
df_books = pd.read_csv(
	'./Data/bestsellers-with-categories.csv',
	sep=",",
	header=0
)
df_books.columns
```

```{python}
df_books = pd.read_csv(
	'./Data/bestsellers-with-categories.csv',
	sep=",",
	header=0,
	names=['Nombre', 'Autor', 'Valoracion', 'Reseñas', 'Precio', 'Año', 'Genero']
)
df_books
```

### JSON

Podemos cargar el archivo JSON como un DataFrame por default, u otra forma de llevar la estructura JSON a una estructura de Pandas como una Series

```{python}
json_per_default = pd.read_json('./Data/hpcharactersdataraw.json')
json_per_default
```

podemos indexar una lista en raw del formato llave valor del JSON

```{python}
pd.read_json('./Data/hpcharactersdataraw.json',typ='Series')
```

## Filtrado con loc y iloc

Cuando queremos navegar por un dataFrame estas funciones permiten filtrar datos de manera más específica

```{python}
df_books = pd.read_csv('./data/bestsellers-with-categories.csv')
df_books
df_books[0:4]
```
### Filtrado por columnas

Filtrar una columna

```{python}
df_books['Name']
```

Filtrar dos o mas columnas

```{python}
df_books[['Name','Author','Year']]
```

### Filtrado con loc

Acceda a un grupo de filas y columnas por etiqueta(s) o una matriz booleana.

A diferencia del el slicing normal, que corta por la posición del index con dataframe. loc tienes la posición de start y stop para filtrar.

#### Filtrar con slicing

```{python}
df_books.loc[0:4]
```

#### Filtrar varios tags

```{python}
df_books.loc[0:4, ['Name','User Rating','Reviews']]
```

#### Filtrar y modificar

```{python}
df_books.loc[0:4, ['User Rating']] * 20
```

#### Filtrar por condición

>Devuelve una lista booleana de quien cumple la condición

```{python}
df_books.loc[:, ['Author']] == 'Jen Sincero	'
```

### Filtrado con iloc

Indexación puramente basada en la ubicación de enteros para la selección por posición.

#### Filtrar con Slicing

```{python}
df_books.iloc[:]
```

#### Filtrar con Indice

```{python}
df_books.iloc[:,0:3]
```

#### Buscar un dato especifico

```{python}
df_books.iloc[1,3]
```

## Agregar o eliminar datos

Partimos con nuestro dataFrame

```{python}
df_books = pd.read_csv('./data/bestsellers-with-categories.csv')
df_books.head(2)
```
### Eliminar columnas

#### Sin modificar el DataFrame

```{python}
df_books.drop('Genre',axis=1).head(2)
df_books.head(2)
```

#### Remplazando el DataFame original

##### utilizando `inplace`

```{python}
df_books.drop('Genre', axis=1, inplace=True)
df_books.head(2)
```

##### Cambiando el valor de referencia en memoria

```{python}
df_books = df_books.drop('Year',axis=1)
df_books.head(2)
```

##### Usando Python Vainilla

```{python}
del df_books['Price']
df_books.head(2)
```

### Eliminar filas
 Podemos eliminar filas de la misma manera que con las columnas simplemente cambiando el valor del axis

```{python}
df_books.drop(0,axis=0).head(2)
```

#### Eliminar una lista de filas

##### Utilizando un array
```{python}
df_books.drop([0,1,2],axis=0).head(2)
```

##### Utilizando `range()`

```{python}
df_books.drop(range(0,10), axis=0).head(2)
```

### Agregar columnas

Mostremos primero nuestro DataFrame e importamos NumPy para asignar el valor nulo
```{python}
import numpy as np

df_books.head(2)
```

#### Agregar una columna con valores nulos
```{python}
df_books['Nueva Columna'] = np.nan
df_books.head(2)
```
#### Asignando datos a una columna

Creamos un array de datos con el numero de elementos de nuestro DataFrame

```{python}
data = np.arange(0, df_books.shape[0])
#data
```
Asignamos estos valores a una nueva columna

> *Una regla es que todo rango que vaya a asignar al DataFrame debe tener la misma longitud en columnas y filas para que no haya error*

```{python}
df_books['Rango'] = data
df_books.head(2)
```

### Agregar filas

Para añadir filas se utiliza la función `append` de Python añadiendo como parámetro una lista, diccionario o añadiendo los valores manualmente.

Podemos por ejemplo duplicar los datos de nuestro DataFrame

```{python}
df_books.append(df_books)
```

## Manejo de datos nulos

En muchas ocasiones nos encotraremos con datos nulos, podemos entonces trabajar con ellos

Partiendo de el suguiente ejemplo de DataFrame

```{python}
dict = {'Col1':[1,2,3,np.nan],
'Col2':[4, np.nan,6,7],
'Col3':['a','b','c', None]}

df = pd.DataFrame(dict)
df
```
### Identificar valores nulos en un DataFrame

#### forma booleana

```{python}
df.isnull()
```

#### Forma numerica

```{python}
df.isnull() * 1
```
### Sustituir los valores nulos

#### Por una cadena

```{python}
df.fillna('Missing')
```

#### Por una medida estadística realizada con los valores de las columnas

```{python}
df.fillna(df.mean())
```

#### por valores de interpolación

```{python}
df.interpolate()
```

### Eliminar datos nulos

```{python}
df.dropna()
```

## Filtrado por conciciones

Dado nuestro DataFrame

```{python}
df_books = pd.read_csv('./data/bestsellers-with-categories.csv')
df_books.head(2)
```

### Mostrar datos mayores a cierto valor

mostramos un DataFrame booleano con los datos que cumplen la condicion

```{python}
mayor_a_2016 = df_books['Year'] > 2016
df_books[mayor_a_2016].head(4)
```

Podemos directamente colocar la condición como parámetro

```{python}
df_books[df_books['Year'] > 2016].head(4)
```

### Mostrar datos que coincidan con cierto valor

```{python}
genre_fiction = df_books['Genre'] == "Fiction"
df_books[genre_fiction].head(4)
```

### Multiples condiciones

```{python}
df_books[genre_fiction & mayor_a_2016]
```

### Filtrado con negacion

```{python}
df_books[~mayor_a_2016]
```

### Filtrado contenga una palabra especifica en una cadena de texto

```{python}
smith_surname = df_books['Author'].str.contains('Mel')
df_books[smith_surname]
```

## Funciones principales

### `.info()`

Mostrar información acerca de los datos que contiene el DataFrame

```{python}
df_books.info()
```

### `.describe()`

Obtener diferentes datos estadísticos de las columnas numéricas

```{python}
df_books.describe()
```

### `.tail()`

Mostrar los últimos 5 registros del DataFrame

```{python}
df_books.tail()
```

### `.memory_usage()`

Obtener el uso de la memoria de cada columna

```{python}
df_books.memory_usage(deep=True)
```

### `.value_counts()`

Obtener *cuantos datos* tenemos de algo en específico

```{python}
df_books['Author'].value_counts()
```

### `.drop_duplicates()`

Eliminar registros duplicados

```{python}
df_books.drop_duplicates()
```

### `.sort_values()`

Ordenar los registros según valores de la columna

#### Orden ascendente

```{python}
df_books.sort_values('Year')
```

#### Orden descendente

```{python}
df_books.sort_values('Year', ascending=False)
```

## Groupby

Permite agrupar datos en función de los demás. Es decir, hacer el análisis del DataFrame en función de una de las columnas.

### `.count()`

Agrupar por **Author** y mostrar el *conteo* de los datos de las demás columnas

```{python}
df_books.groupby('Author').count()
```

Agrupar por **‘Author - Year’** y contar los valores de las demás columnas

```{python}
df_books.groupby(['Author','Year']).count()
```

### `.median()`

Agrupar por **Author** y mostrar la *media* de los datos de las demás columnas

```{python}
df_books.groupby('Author').median()
```

> La columna **Author**, en los casos anteriores, pasa a ser el índice.

### `.loc()`

Podemos usar `loc()` y acceder a un dato específico del DataFrame. Agrupar por **Author** y mostrar la **suma** de los valores de las demás columnas para *William Davis*

```{python}
df_books.groupby('Author').sum().loc['William Davis']
```

### `.reset_index()`

Agrupar por **Author** y mostrar la **suma** de los valores de las demás columnas. Colocar los *índices* que el DataFrame trae por defecto

```{python}
df_books.groupby('Author').sum().reset_index()
```

### `.agg()`

Permite aplicar varias funciones al DataFrame una vez agrupado según una columna específica. 

Agrupar por **Author** y mostrar el *mínimo* y *máximo* de las demás columnas

```{python}
df_books.groupby('Author').agg(['min','max'])
```

Agrupar por **Author**, obtener el *mínimo* y *máximo* de la columna **‘Reviews’** y sumar los valores de la columna **‘User Rating’**

```{python}
df_books.groupby('Author').agg({'Reviews':['min','max'], 'User Rating':'sum'})
```

## Combinando DataFrames

Existen diferentes formas de fusionar dos DataFrames. Esto se hace a través de la lógica de combinación

### **Left join**

Da prioridad al DataFrame de la izquierda. Trae siempre los datos de la izquierda y las filas en común con el DataFrame de la derecha.

### **Right join**

Da prioridad al DataFrame de la derecha. Trae siempre los datos de la derecha y las filas en común con el DataFrame de la izquierda.

### **Inner join**

Trae solamente aquellos datos que son común en ambos DataFrame

### **Outer join**

Trae los datos tanto del DataFrame de la izquierda como el de la derecha, incluyendo los datos que comparten ambos.

## Merge y concat

### concat

Permite combinar dos DataFrames a nivel de filas. Crecimiento vertical

#### Crear un DataFrame nuevo

```{python}
df1 = pd.DataFrame({'A':['A0', 'A1', 'A2','A3'],
        'B':['B0', 'B1', 'B2','B3'],
	'C':['C0', 'C1', 'C2','C3'],
	'D':['D0', 'D1', 'D2','D3']})


df2 = pd.DataFrame({'A':['A4', 'A5', 'A6','A7'],
	'B':['B4', 'B5', 'B6','B7'],
	'C':['C4', 'C5', 'C6','C7'],
	'D':['D4', 'D5', 'D6','D7']})
```
```{python}
print(f'DataFrame 1: \n {df1} \n DataFrame 2: \n {df2}')
```

#### Concatenar los DataFrames

```{python}
pd.concat([df1,df2])
```

#### Corregir los indices

```{python}
pd.concat([df1,df2], ignore_index= True)
```

#### Por *axis 1*

```{python}
pd.concat([df1,df2], axis = 1)
```

### Merge

Permite combinar dos DataFrames a nivel de columnas. La organización por columnas no va a ser la misma para ambos DataFrames, por tanto, se crearan valores `NaN` para rellenar los espacios vacíos. Crecimiento horizontal

#### Key en común

```{python}
izq = pd.DataFrame({'key' : ['k0', 'k1', 'k2','k3'],
 'A' : ['A0', 'A1', 'A2','A3'],
'B': ['B0', 'B1', 'B2','B3']})

der = pd.DataFrame({'key' : ['k0', 'k1', 'k2','k3'],
 'C' : ['C0', 'C1', 'C2','C3'],
'D': ['D0', 'D1', 'D2','D3']})
```
Unir el DataFrame **Der** a **Izq**

```{python}
izq.merge(der)
```

#### Sin columnas en común

```{python}
izq = pd.DataFrame({'key' : ['k0', 'k1', 'k2','k3'],
 'A' : ['A0', 'A1', 'A2','A3'],
'B': ['B0', 'B1', 'B2','B3']})

der = pd.DataFrame({'key_2' : ['k0', 'k1', 'k2','k3'],
 'C' : ['C0', 'C1', 'C2','C3'],
'D': ['D0', 'D1', 'D2','D3']})
```

Debemos especificar las llaves

```{python}
izq.merge(der, left_on = 'key', right_on='key_2')
```

#### Cuando hay algún `NaN` en nuestro DataFrame

```{python}
izq = pd.DataFrame({'key' : ['k0', 'k1', 'k2','k3'],
 'A' : ['A0', 'A1', 'A2','A3'],
'B': ['B0', 'B1', 'B2','B3']})

der = pd.DataFrame({'key_2' : ['k0', 'k1', 'k2',np.nan],
 'C' : ['C0', 'C1', 'C2','C3'],
'D': ['D0', 'D1', 'D2','D3']})
```

```{python}
izq.merge(der, left_on = 'key', right_on='key_2', how='left')
```

## JOIN

Es otra herramienta para hacer exactamente lo mismo, una combinación. La diferencia es que `join` va a ir a los índices y no a columnas específicas.

```{python}
izq = pd.DataFrame({'A': ['A0','A1','A2'],
  'B':['B0','B1','B2']},
  index=['k0','k1','k2'])

der = pd.DataFrame({'C': ['C0','C1','C2'],
  'D':['D0','D1','D2']},
  index=['k0','k2','k3'])
```

### Combinar **izq** con **der**

```{python}
izq.join(der)
```

### Traer todos los datos aunque no hagan match

```{python}
izq.join(der, how = 'outer')
```

> `join` puede considerase como un caso específico de merge, pero más eficiente

## Pivot y Melt

Son funciones que sirven para cambiar la estructura de nuestro DataFrame de acuerdo a nuestras necesidades.

### Pivot

Pivot, básicamente, transforma los valores de determinadas columnas o filas en los índices de un nuevo DataFrame, y la intersección de estos es el valor resultante.

Partamos del siguiente DataFrame

```{python}
df_books.head()
```
Aplicamos `.pivot_table()`

```{python}
df_books.pivot_table(index='Author',columns='Genre',values='User Rating')
```

Como resultado, los valores de Author pasan a formar el índice por fila y los valores de Genre pasan a formar parte de los índices por columna, y el User Rating se mantiene como valor.

#### `aggfunc`

```{python}
df_books.pivot_table(index='Genre',columns='Year', values='User Rating',aggfunc='sum')
```

En este caso tenemos por cada género, la suma a lo largo de los años.

También podemos obtener la media, la desviación estándar, el conteo, la varianza, etc. Únicamente con cambiar el parámetro `aggfunc` que traduce la función de agrupamiento.

```{python}
df_books.pivot_table(index='Genre', columns='Year', values='User Rating'
												,aggfunc= [min, max, np.mean])
```

### Melt

El método melt toma las columnas del DataFrame y las pasa a filas, con dos nuevas columnas para especificar la antigua columna y el valor que traía.

```{python}
df_books[['Name','Genre']].head(5)
```

Aplicando `melt()`

```{python}
df_books[['Name','Genre']].head(5).melt()
```

Ahora cada resultado de las dos columnas pasa a una fila de este modo a tipo **llave**:**valor**.

Podemos utilizar melt también de la siguiente forma

```{python}
df_books.melt(id_vars='Year',value_vars='Genre')
```

Simplemente, podemos seleccionar las columnas que no quiero hacer `melt` usando el parámetro `id_vars`. Para este caso **Year** y también la única columna que quiero aplicar el `melt`, para este caso **Genre** con la propiedad `value_vars`.

## Apply

Es un comando muy poderoso que nos deja aplicar funciones a nuestro DataFrame

```{python}
df_books.head(2)
```

Creamos nuestra función

```{python}
def two_times(value):
		return value * 2
```

Lo aplicamos a la columna de **User Rating**

```{python}
df_books['User Rating'].apply(two_times)
```

Podemos guardar los resultados en una nueva columna

```{python}
df_books['User Rating2'] = df_books['User Rating'].apply(two_times)
df_books.head(5)
```

### Utilizando **lambda functions**

```{python}
df_books['User Rating2'] =df_books['User Rating'].apply(lambda x: x* 3)
df_books.head()
```

Apply en varias columnas con condiciones, hay que especificar a que los vamos a aplicar (filas o columnas)

```{python}
df_books.apply(lambda x: x['User Rating'] * 2 if x['Genre'] == 'Fiction' else x['User Rating'], axis = 1)
```

Puedes usar funciones que reciban más argumentos especificando los demás argumentos en `args`. Por ejemplo una función que convierta el **rating** desde cualquier base a cualquier base sería

```{python}
# Una función con parametros
def convert_rating_base(rating, current_base, new_base):
    # Convertimos el Rating de la base actual a la nueva
		return rating * new_base / current_base

# Apply y se pasan todos los demás argumentos después del primero en args
df_books["User Rating"].apply(convert_rating_base, args=(5, 7))
```

> Recordemos que podemos seleccionar una columna también de esta forma `df.Name` (Siempre y cuando su nombre no contenga espacios)